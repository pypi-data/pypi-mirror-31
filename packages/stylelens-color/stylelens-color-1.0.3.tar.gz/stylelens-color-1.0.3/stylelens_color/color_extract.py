# coding: utf-8
"""
    stylelens-color

    This is a API document for Object Detection on fashion items\"

    OpenAPI spec version: 0.0.1
    Contact: devops@bluehack.net
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

from __future__ import absolute_import

import os
import grpc
import numpy as np
import tensorflow as tf
from preprocessing import inception_preprocessing

from .grpc import color_extract_pb2_grpc
from .grpc import color_extract_pb2

CHUNK_SIZE = 4 * 1024

GPU_HOST = os.environ['COLOR_GRPC_HOST']
GPU_PORT = os.environ['COLOR_GRPC_PORT']

TMP_FILE = '/Users/lion/img.jpg'

class ExtractColor(object):
  def __init__(self, use_gpu=False):
    self.use_gpu = use_gpu

    if use_gpu == False:
      try:
        #MODEL = os.environ['COLOR_GRAPH']
        MODEL = '/Users/lion/PycharmProjects/stylelens-color/color_classification_model.pb'
        LABEL = '/Users/lion/PycharmProjects/stylelens-color/labels.txt'
      except:
        print("!!! Need to define environment variable: CLASSIFY_GRAPH=/path/to/model.pb")

      print(MODEL)
      with tf.gfile.FastGFile(MODEL, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        _ = tf.import_graph_def(graph_def, name='')

      with tf.Session() as self.sess:
        self.softmax_tensor = self.sess.graph.get_tensor_by_name('InceptionV3/Predictions/Softmax:0')

  def extract_color(self, file):

    image_data = tf.gfile.FastGFile(file, 'rb').read()

    if self.use_gpu:
      print('use GPU')
      channel = grpc.insecure_channel(GPU_HOST + ':' + GPU_PORT)
      stub = color_extract_pb2_grpc.ExtractStub(channel)
      response = stub.GetColor(color_extract_pb2.ColorRequest(file_data=image_data))
      ret={}

      ret['class_code'] = response.color_code
      ret['class_score'] = response.color_score

      print(ret)
      return ret

    else:
      print('use CPU')
      label_dic = []
      LABEL = '/Users/lion/PycharmProjects/stylelens-color/labels.txt'
      #LABEL = os.environ['COLOR_LABEL']

      image_data = tf.image.decode_jpeg(image_data, channels=3)
      image_data = inception_preprocessing.preprocess_image(image_data, 299, 299, is_training=False)
      image_data = tf.expand_dims(image_data, 0)

      # label 받아오기
      label_f = open(LABEL, 'rb')
      lines = label_f.readlines()
      for w in lines:
        w = str(w).replace('b\'', "")
        w = w.replace("\\n", "")
        labels_data = w.split(':')
        label_dic.append(labels_data[1])

      with tf.Session() as self.sess:
        img = image_data.eval()
        img = img.tolist()
        predict_color = self.sess.run(self.softmax_tensor, {'input:0': img})
        predict_color = np.squeeze(predict_color)
        color = predict_color.argmax()

        answer_score = predict_color[color]
        answer_label = label_dic[color]

        return answer_label, answer_score
