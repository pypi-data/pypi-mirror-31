Metadata-Version: 1.2
Name: textgenrnn
Version: 1.2
Summary: Pretrained character-based neural network for easily generating text.
Home-page: https://github.com/minimaxir/textgenrnn
Author: Max Woolf
Author-email: max@minimaxir.com
License: MIT
Description: 
        Generate text using a pretrained neural network with a few lines of code,
        or easily train your own text-generating neural network of any size
        and complexity on any text dataset.
        
        * A modern neural network architecture which utilizes new techniques as
        attention-weighting and skip-embedding to accelerate training
        and improve model quality.
        * Able to train on and generate text at either the
        character-level or word-level.
        * Able to configure RNN size, the number of RNN layers,
        and whether to use bidirectional RNNs.
        * Able to train on any generic input text file, including large files.
        * Able to train models on a GPU and then use them with a CPU.
        * Able to utilize a powerful CuDNN implementation of RNNs
        when trained on the GPU, which massively speeds up training time as
        opposed to normal LSTM implementations.
        * Able to train the model using contextual labels,
        allowing it to learn faster and produce better results in some cases.
        
Keywords: deep learning,tensorflow,keras,text generation
Platform: UNKNOWN
Requires-Python: >=3
