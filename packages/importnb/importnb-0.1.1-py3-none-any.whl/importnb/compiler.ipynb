{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding\n",
    "\n",
    "If a notebook is imported, it should provide a natural __traceback__ experience similar to python imports.  The `importnb` importer creates a just decoder object that retains line numbers to the raw json when the notebook is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from json.decoder import JSONObject, JSONDecoder, WHITESPACE, WHITESPACE_STR    \n",
    "    from nbformat import NotebookNode\n",
    "    class LineNoDecoder(JSONDecoder):\n",
    "        \"\"\"A JSON Decoder to return a NotebookNode with lines numbers in the metadata.\"\"\"\n",
    "        def __init__(self, *, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None):\n",
    "            from json.scanner import py_make_scanner    \n",
    "            super().__init__(object_hook=object_hook, parse_float=parse_float, parse_int=parse_int, parse_constant=parse_constant, strict=strict, \n",
    "                             object_pairs_hook=object_pairs_hook)\n",
    "            self.parse_object = self.object\n",
    "            self.scan_once = py_make_scanner(self)\n",
    "            \n",
    "        def object(\n",
    "            self, \n",
    "            s_and_end, \n",
    "            strict, scan_once, object_hook, object_pairs_hook, memo=None, _w=WHITESPACE.match, _ws=WHITESPACE_STR\n",
    "        ) -> (NotebookNode, int):\n",
    "            object, next = JSONObject(s_and_end, strict, scan_once, object_hook, object_pairs_hook, memo=memo, _w=_w, _ws=_ws)\n",
    "\n",
    "            if 'cell_type' in object: \n",
    "                object['metadata'].update({\n",
    "                    'lineno':  len(s_and_end[0][:next].rsplit('\"source\":', 1)[0].splitlines())\n",
    "                })\n",
    "                \n",
    "            for key in ('source', 'text'): \n",
    "                if key in object: object[key] = ''.join(object[key])\n",
    "            return NotebookNode(object), next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation\n",
    "\n",
    "Compilation occurs in the __3__ steps:\n",
    "\n",
    "1. Text is transformed into a valid source string.\n",
    "2. The source string is parsed into an abstract syntax tree\n",
    "3. The abstract syntax compiles to valid bytecode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from IPython.core.compilerop import CachingCompiler\n",
    "    from dataclasses import dataclass, field\n",
    "    \n",
    "    class Compiler(CachingCompiler):\n",
    "        \"\"\"{Shell} provides the IPython machinery to objects.\"\"\"\n",
    "        filename: str = '<Shell>'            \n",
    "        @property\n",
    "        def ip(Compiler): \n",
    "            \"\"\"The current interactive shell\"\"\"\n",
    "            from IPython import get_ipython\n",
    "            from IPython.core.interactiveshell import InteractiveShell\n",
    "            return get_ipython() or InteractiveShell()\n",
    "        \n",
    "        def ast_transform(Compiler, node):\n",
    "            for visitor in Compiler.ip.ast_transformers: \n",
    "                node = visitor.visit(node)\n",
    "            return node\n",
    "        \n",
    "        @property\n",
    "        def transform(Compiler): return Compiler.ip.input_transformer_manager.transform_cell\n",
    "\n",
    "        def compile(Compiler, ast): \n",
    "            \"\"\"Compile AST to bytecode using the an IPython compiler.\"\"\"\n",
    "            return (Compiler.ip and Compiler.ip.compile or CachingCompiler())(ast, Compiler.filename, 'exec')\n",
    "                \n",
    "        def ast_parse(Compiler, source, filename='<unknown>', symbol='exec', lineno=0): \n",
    "            return ast.increment_lineno(super().ast_parse(source, Compiler.filename, 'exec'), lineno)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import ast, sys\n",
    "    from json import load, loads\n",
    "    from nbformat import NotebookNode, read, reads\n",
    "    from pathlib import Path\n",
    "    from nbconvert.exporters.markdown import MarkdownExporter\n",
    "    from nbconvert.exporters.notebook import NotebookExporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @dataclass\n",
    "    class Code(NotebookExporter, Compiler):\n",
    "        \"\"\"An exporter than returns transforms a NotebookNode through the InputSplitter.\n",
    "        \n",
    "        >>> assert type(Code().from_filename('compiler.ipynb')) is NotebookNode\"\"\"\n",
    "        filename: str = '<module exporter>'\n",
    "        name: str = '__main__'\n",
    "        decoder: type = LineNoDecoder\n",
    "            \n",
    "        def __post_init__(self): NotebookExporter.__init__(self) or Compiler.__init__(self)\n",
    "                \n",
    "        def from_file(Code,file_stream, resources=None, **dict): \n",
    "            for str in ('name', 'filename'): setattr(Code, str, dict.pop(str, getattr(Code, str)))\n",
    "            return Code.from_notebook_node(\n",
    "                NotebookNode(**load(file_stream, cls=Code.decoder)), resources, **dict)\n",
    "        \n",
    "        def from_filename(Code,  filename, resources=None, **dict):\n",
    "            Code.filename, Code.name = filename, Path(filename).stem\n",
    "            return super().from_filename(filename, resources, **dict)\n",
    "\n",
    "        def from_notebook_node(Code, nb, resources=None, **dict): \n",
    "            for cell in nb['cells']:\n",
    "                if cell['cell_type'] == 'code':\n",
    "                    cell.source = Code.from_code_cell(cell, **dict)\n",
    "            return nb\n",
    "        \n",
    "        def from_code_cell(Code, cell, **dict):  \n",
    "            return Code.transform(cell['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class AST(Code):\n",
    "        \"\"\"An exporter than returns parsed ast.\n",
    "        \n",
    "        >>> assert type(AST().from_filename('compiler.ipynb')) is ast.Module\"\"\"\n",
    "        def from_notebook_node(AST, nb: NotebookNode, resource: dict=None, **dict):         \n",
    "            return AST.ast_transform(ast.fix_missing_locations(ast.Module(body=sum((\n",
    "                AST.ast_parse(\n",
    "                    AST.from_code_cell(cell, **dict), lineno=cell['metadata'].get('lineno', 1)\n",
    "                ).body for cell in nb.cells if cell['cell_type']=='code'\n",
    "            ), []))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Compile(AST):\n",
    "        \"\"\"An exporter that returns compiled and cached bytecode.\n",
    "        \n",
    "        >>> assert Compile().from_filename('compiler.ipynb')\"\"\"        \n",
    "        def from_notebook_node(Compile, nb, resources: dict=None, **dict):\n",
    "            return Compile.compile(super().from_notebook_node(nb, resources, **dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook compiler.ipynb to script\n",
      "[NbConvertApp] Writing 5542 bytes to compiler.py\n"
     ]
    }
   ],
   "source": [
    "    if __name__ ==  '__main__':\n",
    "        !jupyter nbconvert --to script compiler.ipynb\n",
    "        __import__('doctest').testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "29px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
