# Default arguments for the Markov Chain Monte Carlo sampler

sampler:
  mcmc:
    # Number of discarded burn-in samples
    burn_in: 100
    # Error criterion: max attempts (= weight-1) before deciding the chain is stuck
    max_tries: 100
    # File name (including path) or numpy defining a covariance matrix for the proposal
    # If numpy matrix, pass a list of the parameters in the matrix through covmat_params
    covmat: null
    covmat_params: null
    # Update output file(s) every X accepted samples
    output_every: 5
    # Overall scale of the proposal pdf (increase for longer steps)
    propose_scale: 2.4
    # Number of steps*dimension after which convergence is checked
    # and a proposal is learnt (if `learn_proposal: True`)
    check_every_dimension_times: 40
    # Proposal covariance matrix learning
    # -----------------------------------
    learn_proposal: False
    # Don't learn if convergence is worse than...
    learn_proposal_Rminus1_max: 2.
    # (even earlier if a param is not in the given covariance matrix)
    learn_proposal_Rminus1_max_early: 30.
    # ... or if it is better than... (no need to learn, already good!)
    learn_proposal_Rminus1_min: 0.
    # Convergence and stopping
    # ------------------------
    # Maximum number of posterior evaluations
    max_samples: inf
    # Gelman-Rubin R-1 on means (requires MPI!)
    Rminus1_stop: 0.05
    # Gelman-Rubin R-1 on std deviations (requires MPI!)
    Rminus1_cl_stop: 0.3
    Rminus1_cl_level: 0.95
    # Exploiting speed hierarchy
    # --------------------------
    # Method I: Oversampling of each parameters block relative to it speed
    oversample: False  # NB: still WIP in the beta version!
    # Method II: Dragging: simulates jumps on slow params when varying fast ones
    # Set to True, or a factor of the time of a jump on the slow block
    drag: False
    # Callback function
    # -----------------
    callback_function: null
    callback_every: 1000
