##  cluster settings

# id: <id of the cluster to be created, reccommended to specify with --id command line parameter>

# Toolkit configuration [Required] You can use `aztk toolkit` command to find which are the available tookits
toolkit:
  software: spark
  version: 2.2.0
  # Which environemnt is needed for spark anaconda, r, miniconda
  environment: {environment}
  # Optional version for the environment
  # environment_version:

  # Optional docker repository(To bring your custom docker image. Just specify the Toolkit software, version and environemnt if using default images)
  # docker_repo: <name of docker image repo (for more information, see https://github.com/Azure/aztk/blob/master/docs/12-docker-image.md)>


# vm_size: <vm-size, see available options here: https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/>
vm_size: standard_a2

# size: <number of dedicated nodes in the cluster, not that clusters must contain all dedicated or all low priority nodes>
size: 2

# size_low_pri: <number of low priority nodes in the cluster, mutually exclusive with size setting>


# username: <username for the linux user to be created> (optional)
username: spark

# **DEPRECATED** Use plugins instead
# custom_scripts:
#   - script: </path/to/script.sh or /path/to/script/directory/>
#     runOn: <master/worker/all-nodes>
#   - script: <./relative/path/to/other/script.sh or ./relative/path/to/other/script/directory/>
#     runOn: <master/worker/all-nodes>

# To add your cluster to a virtual network provide the full arm resoruce id below
# subnet_id: /subscriptions/********-****-****-****-************/resourceGroups/********/providers/Microsoft.Network/virtualNetworks/*******/subnets/******

# Enable plugins
plugins:
  # - name: spark_ui_proxy
  # - name: jupyterlab
  # - name: jupyter
  # - name: hdfs
  # - name: rstudio_server

# Allow master node to also be a worker <true/false> (Default: true)
# worker_on_master: true

# wait: <true/false>
wait: false
